<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Categorical Perception of ASL - Introduction</title>
        <<link rel="icon" href="./favicon.ico" type="image/x-icon">
        <link rel="stylesheet" href="./css/style.css">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">
        <script src="./script/script.js" defer></script>
    </head>

    <body>
        <div id="site-area">
            <header id="top">        
                
                <div id="menu-box">
                    <input type="checkbox" id="hamburger-input" class="burger-shower">
                    <label id="hamburger-icon" for="hamburger-input">
                        <i class="fa-solid fa-bars" id="open-menu"></i>
                        <i class="fa-solid fa-x" id="close-menu"></i> 
                    </label>   

                    <nav id="dropdown-menu"> 
                        <ul>
                            <li><a href="index.html">Home</a></li>
                            <li><a href="about.html">About</a></li>
                            <li><a href="introduction.html">Introduction</a></li>
                            <li><a href="methods.html">Methods</a></li>
                            <li><a href="results.html">Results</a></li>
                            <li><a href="discussion.html">Discussion</a></li>
                            <li><a href="references.html">References &amp; Appendices</a></li>
                            <li><a href="https://github.com/SRDMoss/cp-asl" target="_blank">Github</a></li>
                        </ul>
                    </nav> 
                </div>
                
                <section id="full-title">
                    <h1 id="page-title">Categorical Perception of Palm Orientation in American Sign Language</h1>   
                    <span id="byline">by Stephen Richard DeVilbiss Moss</span>              
                </section>                            
            </header>
            
            <main>
                <h2>Introduction</h2>

                <article id="CP">
                    <h3>Categorical Perception</h3>
                    <p>The study of human perception has often revealed that observations in the world are not always perceived in their genuine states. Scientific 
                        research in many areas has revealed that the human brain perceives things in contrast to their nature based on individual experience, environment, 
                        context, intuition and more. The human mind changes what is observed, and this is of practical concern to language researchers. One phenomenon 
                        of note within both psychophysics and language research is known as Categorical Perception (<abbr title="Categorical Perception">CP</abbr>).</p>
                    <p>Within language, this phenomenon is observed by looking at characteristics of the most basic distinguishable parts, or features, that make up units 
                        of speech. Isolating these parameters allows observation along a single-dimentional continuum. <dfn>Categorical Perception</dfn> occurs when language
                        users receive linguistic stimuli along this continuum and&mdash;rather than perceiving the stimulus as varied along the continuum, therefore
                        creating an infininte number of unique utterances&mdash;categorize the elements as memebers of discrete language categories along the continuum. On its own, 
                        this is unremarkable, but CP describes a specific type of warping of the perceptual range. One distinguishing feature of Categorical Perception is observed 
                        when an experienced speaker is presented with paired stimuli along this continuum. If these stimuli are varied equally, the speaker will have more difficulty 
                        distinguishing between each if the speaker perceives them to be of the same category and an easier time if the tokens cross boundaries and are perceived to 
                        be in separate categories <sup>[<a href="references.html#ref6">6</a>, <a href="references.html#ref7">7</a>]</sup>.</p>
                    <p>The magnitude of CP effects can vary between different continua. Pronounced CP effects are observed in the production of stop-consonants along the continuum of time 
                        delay between the burst and the subsequent onset of vocal fold activation. <em>Listen to an example of this below!</em>  Weaker CP effects are found when measuring position of the tongue along the 
                        two-dimensional range of space that is utilized in articulation of vowel sounds. These slighter effects leave room for discussion of competing models, e.g. the Perceptual 
                        Magnet Effect (PME) described by Patricia Kuhl. The PME is characterized by the best exemplar for the category rather than by the category&apos;s boundaries. Testing shows 
                        that the exemplar is effectively <em>pulling</em> the surrounding stimuli closer and making discrimination more difficult closer to the exemplar and easier when the stimuli are 
                        further from the center of the category (Kuhl, 1991). </p>            
                    <p>Beyond spoken language, CP has been observed in visual and non-linguistic realms as well: facial expressions <sup>[<a href="references.html#ref3">3</a>]</sup>, object recognition 
                        <sup>[<a href="references.html#ref5">5</a>]</sup>, colors <sup>[<a href="references.html#ref10">10</a>]</sup>, and American Sign Language (ASL) <sup>[<a href="references.html#ref1">1</a>, 
                            <a href="references.html#ref2">2</a>, <a href="references.html#ref4">4</a>, <a href="references.html#ref8">8</a>]</sup>. </p>
                </article>

                <article id="ASL">
                    <h3>American Sign Language</h3>
                    <p><dfn>American Sign Language</dfn>  (<abbr title="American Sign Language">ASL</abbr>) is the primary language for deaf and hard-of-hearing individuals in North America 
                        <sup>[<a href="references.html#ref12">12</a>]</sup>. Rather than taking advantage of the aural/oral pathways of spoken languages, ASL is produced with gestures of the hands and 
                        body and received visually. ASL exhibits a full range of phonological, morphological, and syntactic structures as do spoken languages. <sup>[<a href="references.html#ref11">11
                        </a>]</sup>. </p>
                    <p>The phonological characteristics of ASL can be evaluated via several different phonological models. Though each model is different, each model takes into account different 
                        parameters of each sign, which are comparable to features of spoken language phonology. These parameters may be summarized as: movement, location, non-manual signals, 
                        handshape, and palm orientation. </p>
                </article>

                <figure>
                    <h3>Voice Onset Continuum</h3>
                    <audio src="assets/sound/VOT_continuum.wav" controls preload>Unfortunately, this browser does not support .wav formats.</audio>
                    <figcaption>An audio demonstration of a voice-onset-time continuum. Notice, that the word <q>deer</q> begins the spectrum and the word <q>tier</q> is the final word.
                    The only manipulated element in this group of sounds is the duration between the burst of the articulation and the onset of of the voicing (when the vocal folds are activated). 
                    The /d/ sound which begins <q>deer</q> occurs on the spectrum when the voicing begins simultaneously within 0 ms - 10 ms after the articulatory burst. The /t/ sound which begins 
                    the word <q>tier</q> occurs when the voice beguns with a delay of approximately 70 ms after the burst. What American-English speakers will notice is that instead of hearing seven
                    different sounds, thus seven different word samples, they hear several utterances of the words <q>deer</q> and <q>tier.</q> (I hear five <em>deers</em> and two <em>tiers</em>)
                    <br><br>
                    Acquired and used as part of an application covered under the GNU General Public License. Sound sample provided by <a href="http://www.mattwinn.com" target="_blank"> Matthew Winn</a>.
                    </figcaption>
                </figure>  

                <figure>
                    <img class="media"  id="bill" src="assets/img/computer.gif" alt="Bill Vickars signing COMPUTER">
                    <figcaption>The ASL sign for <q>Computer.</q>
                        <br>
                        &copy; <a href="http://www.lifeprint.com" target="_blank">www.Lifeprint.com</a>. Used by permission.                            
                    </figcaption>
                </figure>   

                
                <article id="ASL-parameters">
                    <h3>Parameters of ASL</h3>
                    <ul>
                        <li>Movement</li>
                        <li>Location</li> 
                        <li>Non-Manual Signals                    
                            <ul>
                                <li>Eye-Gaze</li>
                                <li>Facial Expression</li>
                                <li>Shoulder Orientation</li>
                            </ul> 
                        </li>                    
                        <li>HandShape</li>
                        <li>Palm Orientation</li>                                       
                    </ul>
                </article>

         


                <h2>Categorical Perception in American Sign Language</h2>
                <article id="CPASL-1">
                    
                    <p>At the time of this writing, studies have found CP effects in some but not all handshape continua <sup>[<a href="references.html#ref1">1</a>, 
                        <a href="references.html#ref4">4</a>, <a href="references.html#ref8">8</a>, <a href="references.html#ref9">9</a>]</sup>, and no CP effects in location continua (Emmorey, McCullough, & Brentari, 2003; Morford, et al., 2008; 
                        Newport, 1982). While CP has been found in studies of emotional facial expressions (Cheal & Rutherford, 2013), the perception of linguistic non-manual signals remains an 
                        open question. It remains open for movement and palm orientation as well. </p>
                    <p>In traditional studies of CP, an identification or categorization task is paired with a discrimination task to find the boundary between categories and then verify the 
                        increased discriminability near those boundaries. In the identification component of spoken language studies, participants are asked to listen to a tone along an evenly 
                        measured continuum and then identify it as a member of a category denoted by one of two endpoints of the continuum (need citation?). Because of the typical syntactic nature 
                        of ASL, these tasks have been modified typically into an ABX format, where each of the endpoint tokens (A and B) are presented first and then the specific token from along 
                        the continuum (X) is identified by the participant as a member of either category A or category B (need citation). </p>
                    <p>These identification tasks record successful categorization nearly all of the time for native signers, late signers, and sign naïve individuals (need citation?). However, it 
                        seems unlikely that an individual with no experience in signed languages would truly identify phonological categories rather than simply grouping tokens into the nearest 
                        group perceived. Additionally, these tasks do not accurately measure situations in which participants wish to identify more than two categories along the continua, nor 
                        accurately describe differences in actual category continua from that predicted a priori by researchers. There are a few ways in which these studies may be improved to more 
                        accurately reflect existing phonological categories in participants.</p>
                </article>

                <article id="CPASL-2">
                    <p>A long running controversial debate in the realm of sociolinguistics may offer a solution to these types of weaknesses. In their 1969 studies of basic color terms within 
                        languages which contain fewer than 11 color terms, Berlin and Kay presented participants with an array of color chips (See Appendix A), and then ascertained from the 
                        participant for each color term x: “(1) all those chips which he would under any conditions call x. (2) the best, most typical examples of x.” (Berlin & Kay, 1999). The 
                        first task in essence requests category borders, and the second an exemplar for the category. The visual nature of ASL may allow a similar paradigm to account for variances 
                        such as these as well as identify individual variances based on dialect, etc.</p>
                    <p>Assuming this new research method is successful, when paired with traditional discrimination tasks from ASL CP studies, we may begin to develop a basis for answering several 
                        questions. What are the categories along palm orientation continua that are identified by native signers? Do sign naïve individuals continue to identify strong category 
                        boundaries? Is there variation in discriminability along this continuum? Is it the same for native signers and sign naïve individuals? In addition to experience, does 
                        language context influence this? </p>
                </article>    
            </main>
            <footer id="bottom">
                <hr>
                    &copy; 2014, 2015, 2023, Stephen Moss.
                <hr>
            </footer>

            <!-- Modal -->
            <div id="mediaModal" class="modal">                
                <div class="modal-content" id="modalContent">
                    <!-- Dynamic content here -->
                </div>
                <span class="close-btn" id="closeModal">&times;</span>
            </div>
        </div>
    </body>
</html>